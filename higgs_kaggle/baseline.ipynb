{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "In this notebook we prepare a simple solution for the [kaggle challenge on higgs.](https://inclass.kaggle.com/c/mlhep-2016-higgs-detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd datasets; wget -O public_train_10000.root -nc --no-check-certificate https://2016.mlhep.yandex.net/data/higgs/public_train_10000.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can download training sample with 100000 available events\n",
    "# uncomment the below row\n",
    "!cd datasets; wget -O public_train_100000.root -nc --no-check-certificate https://2016.mlhep.yandex.net/data/higgs/public_train_100000.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd datasets; wget -O public_test.root -nc --no-check-certificate https://2016.mlhep.yandex.net/data/higgs/public_test.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the smallest part of training file and test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import root_numpy\n",
    "data = pandas.DataFrame(root_numpy.root2array('datasets/public_train_100000.root'))\n",
    "test = pandas.DataFrame(root_numpy.root2array('datasets/public_test.root'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training features\n",
    "\n",
    "Exclude `event_id`, `target` from the features set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jet3_pt',\n",
       " 'jet3_eta',\n",
       " 'm_jjj',\n",
       " 'mem_phi',\n",
       " 'jet1_pt',\n",
       " 'jet4_phi',\n",
       " 'jet1_phi',\n",
       " 'jet2_eta',\n",
       " 'jet3_btag',\n",
       " 'm_jlv',\n",
       " 'm_wbb',\n",
       " 'jet4_pt',\n",
       " 'jet4_btag',\n",
       " 'jet2_pt',\n",
       " 'jet1_btag',\n",
       " 'm_jj',\n",
       " 'm_wwbb',\n",
       " 'jet2_phi',\n",
       " 'lepton_phi',\n",
       " 'm_bb',\n",
       " 'm_lv',\n",
       " 'jet4_eta',\n",
       " 'jet2_btag',\n",
       " 'lepton_pt',\n",
       " 'mem_pt',\n",
       " 'lepton_eta',\n",
       " 'jet3_phi',\n",
       " 'jet1_eta']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(set(data.columns) - {'event_id', 'target'})\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare high-level features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_level_features = ['m_jj', 'm_jjj', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'm_lv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histograms for each high-level feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_params = {'normed': True, 'bins': 60, 'alpha': 0.4}\n",
    "# create the figure\n",
    "plt.figure(figsize=(16, 25))\n",
    "for n, feature in enumerate(high_level_features):\n",
    "    # add sub plot on our figure\n",
    "    plt.subplot(len(features) // 5 + 1, 3, n+1)\n",
    "    # define range for histograms by cutting 1% of data from both ends\n",
    "    min_value, max_value = numpy.percentile(data[feature], [1, 99])\n",
    "    plt.hist(data.ix[data.target.values == 0, feature].values, range=(min_value, max_value), \n",
    "             label='class 0', **hist_params)\n",
    "    plt.hist(data.ix[data.target.values == 1, feature].values, range=(min_value, max_value), \n",
    "             label='class 1', **hist_params)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def get_validated_trained(fitter, data, features, part):\n",
    "    training_data, validation_data = train_test_split(data, random_state=3747824, train_size=part)\n",
    "    fitter.fit(training_data[features], training_data.target)\n",
    "    results = fitter.predict_proba(validation_data[features])\n",
    "    print 'Validation:', roc_auc_score(validation_data.target, results[:, 1])\n",
    "\n",
    "def get_full_trained(fitter, data, features):\n",
    "    fitter.fit(data[features], data.target)\n",
    "\n",
    "def get_result(fitter, test, features):\n",
    "    return fitter.predict_proba(test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Classifier, Layer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:Theano was already imported and cannot be reconfigured.\n"
     ]
    }
   ],
   "source": [
    "from sknn.platform import cpu64, threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sknn:Initializing neural network with 5 layers, 28 inputs and 2 outputs.\n",
      "DEBUG:sknn:  - Dense: \u001b[1;97mRectifier \u001b[0m Units:  \u001b[1;97m300 \u001b[0m\n",
      "DEBUG:sknn:  - Dense: \u001b[1;97mRectifier \u001b[0m Units:  \u001b[1;97m300 \u001b[0m\n",
      "DEBUG:sknn:  - Dense: \u001b[1;97mRectifier \u001b[0m Units:  \u001b[1;97m300 \u001b[0m\n",
      "DEBUG:sknn:  - Dense: \u001b[1;97mRectifier \u001b[0m Units:  \u001b[1;97m300 \u001b[0m\n",
      "DEBUG:sknn:  - Dense: \u001b[1;97mSoftmax   \u001b[0m Units:  \u001b[1;97m2   \u001b[0m\n",
      "DEBUG:sknn:\n",
      "INFO:sknn:Training on dataset of 60,000 samples with 1,800,000 total size.\n",
      "DEBUG:sknn:  - Using `L2` for regularization.\n",
      "DEBUG:sknn:  - Terminating loop after 66 total iterations.\n",
      "DEBUG:sknn:  - Early termination after 10 stable iterations.\n",
      "DEBUG:sknn:\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:sknn:\r",
      "    1         \u001b[0;94m 8.930e-01\u001b[0m                 N/A           16.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:sknn:\r",
      "    2         \u001b[0;94m 6.938e-01\u001b[0m                 N/A           16.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:sknn:\r",
      "    3         \u001b[0;94m 6.940e-01\u001b[0m                 N/A           16.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:sknn:\r",
      "    4         \u001b[0;94m 6.940e-01\u001b[0m                 N/A           16.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:sknn:\r",
      "    5         \u001b[0;94m 6.939e-01\u001b[0m                 N/A           16.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:sknn:\r",
      "    6         \u001b[0;94m 6.935e-01\u001b[0m                 N/A           16.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout\n",
    ")\n",
    "logger = logging.getLogger('sknn')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "fitter = Pipeline([\n",
    "        ('min/max scaler', MinMaxScaler(feature_range=(0.0, 1.0))),\n",
    "        ('neural network', Classifier(\n",
    "                layers=[\n",
    "                    Layer(\"Rectifier\", units=300),\n",
    "                    Layer(\"Rectifier\", units=300),\n",
    "                    Layer(\"Rectifier\", units=300),\n",
    "                    Layer(\"Rectifier\", units=300),\n",
    "                    Layer(\"Softmax\")\n",
    "                ],\n",
    "                n_iter=66,\n",
    "                random_state=274734,\n",
    "                learning_rate=0.2,\n",
    "                learning_momentum=0.999,\n",
    "                verbose=True,\n",
    "                batch_size=10,\n",
    "                regularize='L2',\n",
    "                weight_decay=0.01\n",
    "    ))])\n",
    "\n",
    "cur_features = features\n",
    "get_validated_trained(fitter, data, cur_features, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of 3000 | elapsed:    1.3s remaining: 66.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "def get_fitter():\n",
    "    fitter = RandomForestClassifier(\n",
    "        3000,\n",
    "        max_depth=33,\n",
    "        n_jobs=-1,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return fitter\n",
    "\n",
    "fitter = get_fitter()\n",
    "cur_features = features\n",
    "new_features = cur_features[:]\n",
    "new_data = data.copy()\n",
    "new_test = test.copy()\n",
    "for i, cur_f in enumerate(cur_features):\n",
    "    if cur_f.startswith('m_'):\n",
    "        for cur_g in cur_features[i + 1:]:\n",
    "            if cur_g.startswith('m_'):\n",
    "                f_name = 'm_diff_%s_%s' % (cur_f, cur_g)\n",
    "                new_data[f_name] = data[cur_f] / data[cur_g]\n",
    "                new_test[f_name] = test[cur_f] / test[cur_g]\n",
    "                new_features.append(f_name)\n",
    "new_data.head()\n",
    "get_full_trained(fitter, new_data, new_features)\n",
    "#get_validated_trained(fitter, new_data, new_features, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>target</th>\n",
       "      <th>lepton_pt</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>mem_pt</th>\n",
       "      <th>mem_phi</th>\n",
       "      <th>jet1_pt</th>\n",
       "      <th>jet1_eta</th>\n",
       "      <th>jet1_phi</th>\n",
       "      <th>...</th>\n",
       "      <th>jet4_eta</th>\n",
       "      <th>jet4_phi</th>\n",
       "      <th>jet4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1</td>\n",
       "      <td>(5421299.97301+0j)</td>\n",
       "      <td>(-24.3297657498+0j)</td>\n",
       "      <td>(632.728385961+0j)</td>\n",
       "      <td>(5810072.05736+0j)</td>\n",
       "      <td>(324.480778877+0j)</td>\n",
       "      <td>(7088333.3927+0j)</td>\n",
       "      <td>(75.0336984188+0j)</td>\n",
       "      <td>(-628.041845405+0j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(321.896043186+0j)</td>\n",
       "      <td>(816.361165102+0j)</td>\n",
       "      <td>(81180.6939785+0j)</td>\n",
       "      <td>(8976519.16873+0j)</td>\n",
       "      <td>(18126930.3969+0j)</td>\n",
       "      <td>(8542375.21261+0j)</td>\n",
       "      <td>(19404433.3865+0j)</td>\n",
       "      <td>(11982746.0311+0j)</td>\n",
       "      <td>(34842988.1681+0j)</td>\n",
       "      <td>(48405143.0547+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>1</td>\n",
       "      <td>(4406.64085382-10440.3480691j)</td>\n",
       "      <td>(-7.28865676809+99.0357121096j)</td>\n",
       "      <td>(-102.329158471+74.7017249853j)</td>\n",
       "      <td>(-4518.82218108+1282.87634954j)</td>\n",
       "      <td>(406.089742316-337.838785852j)</td>\n",
       "      <td>(-16804.2251273-4587.62807946j)</td>\n",
       "      <td>(398.196307412-181.349032318j)</td>\n",
       "      <td>(500.895046357+119.861000708j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(115.546772465+475.990939384j)</td>\n",
       "      <td>(-428.054984952-887.893824144j)</td>\n",
       "      <td>(-179.935167556+10.7879083344j)</td>\n",
       "      <td>(1316.7216786+9273.19743202j)</td>\n",
       "      <td>(-549.237713651+13601.9247298j)</td>\n",
       "      <td>(128.300496094-453.924667721j)</td>\n",
       "      <td>(11566.0863809+19364.8912835j)</td>\n",
       "      <td>(13120.2128331+3103.74473599j)</td>\n",
       "      <td>(18093.0082823+29863.944389j)</td>\n",
       "      <td>(31306.838205+20385.8465256j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>1</td>\n",
       "      <td>(-5380.83726356+13619.8256582j)</td>\n",
       "      <td>(153.654852681+409.158441849j)</td>\n",
       "      <td>(-70.9141241033-1032.21122385j)</td>\n",
       "      <td>(-7709.12358284-1300.60661022j)</td>\n",
       "      <td>(-490.653216636-337.598577703j)</td>\n",
       "      <td>(-2732.74099555+2993.42039603j)</td>\n",
       "      <td>(-158.256097425-218.422013112j)</td>\n",
       "      <td>(581.369191318-430.350948148j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(554.324381492+178.065026119j)</td>\n",
       "      <td>(-250.197348588+148.227219908j)</td>\n",
       "      <td>(-147.742534269+36.9325361747j)</td>\n",
       "      <td>(6872.42733148-5896.04177095j)</td>\n",
       "      <td>(20083.3732922-3461.22101082j)</td>\n",
       "      <td>(-1816.83410464+341.95447713j)</td>\n",
       "      <td>(8147.31831542+12612.6752749j)</td>\n",
       "      <td>(4322.52347107+405.753495554j)</td>\n",
       "      <td>(17668.7951018+40323.1110574j)</td>\n",
       "      <td>(24431.9202624+32478.0342892j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>0</td>\n",
       "      <td>(11246.1414315-6755.97484606j)</td>\n",
       "      <td>(-72.7880904913-178.550321593j)</td>\n",
       "      <td>(190.920513772+237.4080537j)</td>\n",
       "      <td>(7519.61146663-3775.1144496j)</td>\n",
       "      <td>(-81.3251021379-574.916035425j)</td>\n",
       "      <td>(20100.7321953-8639.19305206j)</td>\n",
       "      <td>(-214.446214274+152.06861446j)</td>\n",
       "      <td>(299.652518587-324.622239567j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(-61.9648059859+445.929128328j)</td>\n",
       "      <td>(-40.9793201391-207.713414596j)</td>\n",
       "      <td>(-34.4666359745-125.945142273j)</td>\n",
       "      <td>(3111.3085742+10029.0444708j)</td>\n",
       "      <td>(-3882.78527776+2390.60150768j)</td>\n",
       "      <td>(-399.011978123+3103.97430008j)</td>\n",
       "      <td>(-18134.268758+4369.8005329j)</td>\n",
       "      <td>(-4335.76489347-19327.3488033j)</td>\n",
       "      <td>(-4198.80052076+8739.59602611j)</td>\n",
       "      <td>(11179.4873673-3632.49985006j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>0</td>\n",
       "      <td>(-1749.56741157+2407.81320111j)</td>\n",
       "      <td>(372.723808664-18.2296637898j)</td>\n",
       "      <td>(311.710069031-325.018280842j)</td>\n",
       "      <td>(-2017.25610017-1805.54949022j)</td>\n",
       "      <td>(-523.006823577+77.3812855229j)</td>\n",
       "      <td>(2646.71449848-4623.40210645j)</td>\n",
       "      <td>(319.117782808-23.9335389722j)</td>\n",
       "      <td>(-302.028429999+83.5827503272j)</td>\n",
       "      <td>...</td>\n",
       "      <td>(-127.303987167-80.2030779503j)</td>\n",
       "      <td>(-1294.74533348-137.928477418j)</td>\n",
       "      <td>(118.231513568+61.7688141911j)</td>\n",
       "      <td>(11006.5745471+5095.22134146j)</td>\n",
       "      <td>(12538.4120959-9957.91739448j)</td>\n",
       "      <td>(-1122.23583873-1697.77577789j)</td>\n",
       "      <td>(-6828.50096709-587.104477543j)</td>\n",
       "      <td>(-12066.1287332+1709.35739797j)</td>\n",
       "      <td>(-27544.0632036+2421.36229569j)</td>\n",
       "      <td>(-41289.9915709-5265.04432711j)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id  target                        lepton_pt  \\\n",
       "0   1000001       1               (5421299.97301+0j)   \n",
       "1   1000002       1   (4406.64085382-10440.3480691j)   \n",
       "2   1000003       1  (-5380.83726356+13619.8256582j)   \n",
       "3   1000004       0   (11246.1414315-6755.97484606j)   \n",
       "4   1000005       0  (-1749.56741157+2407.81320111j)   \n",
       "\n",
       "                        lepton_eta                       lepton_phi  \\\n",
       "0              (-24.3297657498+0j)               (632.728385961+0j)   \n",
       "1  (-7.28865676809+99.0357121096j)  (-102.329158471+74.7017249853j)   \n",
       "2   (153.654852681+409.158441849j)  (-70.9141241033-1032.21122385j)   \n",
       "3  (-72.7880904913-178.550321593j)     (190.920513772+237.4080537j)   \n",
       "4   (372.723808664-18.2296637898j)   (311.710069031-325.018280842j)   \n",
       "\n",
       "                            mem_pt                          mem_phi  \\\n",
       "0               (5810072.05736+0j)               (324.480778877+0j)   \n",
       "1  (-4518.82218108+1282.87634954j)   (406.089742316-337.838785852j)   \n",
       "2  (-7709.12358284-1300.60661022j)  (-490.653216636-337.598577703j)   \n",
       "3    (7519.61146663-3775.1144496j)  (-81.3251021379-574.916035425j)   \n",
       "4  (-2017.25610017-1805.54949022j)  (-523.006823577+77.3812855229j)   \n",
       "\n",
       "                           jet1_pt                         jet1_eta  \\\n",
       "0                (7088333.3927+0j)               (75.0336984188+0j)   \n",
       "1  (-16804.2251273-4587.62807946j)   (398.196307412-181.349032318j)   \n",
       "2  (-2732.74099555+2993.42039603j)  (-158.256097425-218.422013112j)   \n",
       "3   (20100.7321953-8639.19305206j)   (-214.446214274+152.06861446j)   \n",
       "4   (2646.71449848-4623.40210645j)   (319.117782808-23.9335389722j)   \n",
       "\n",
       "                          jet1_phi               ...                 \\\n",
       "0              (-628.041845405+0j)               ...                  \n",
       "1   (500.895046357+119.861000708j)               ...                  \n",
       "2   (581.369191318-430.350948148j)               ...                  \n",
       "3   (299.652518587-324.622239567j)               ...                  \n",
       "4  (-302.028429999+83.5827503272j)               ...                  \n",
       "\n",
       "                          jet4_eta                         jet4_phi  \\\n",
       "0               (321.896043186+0j)               (816.361165102+0j)   \n",
       "1   (115.546772465+475.990939384j)  (-428.054984952-887.893824144j)   \n",
       "2   (554.324381492+178.065026119j)  (-250.197348588+148.227219908j)   \n",
       "3  (-61.9648059859+445.929128328j)  (-40.9793201391-207.713414596j)   \n",
       "4  (-127.303987167-80.2030779503j)  (-1294.74533348-137.928477418j)   \n",
       "\n",
       "                         jet4_btag                            m_jj  \\\n",
       "0               (81180.6939785+0j)              (8976519.16873+0j)   \n",
       "1  (-179.935167556+10.7879083344j)   (1316.7216786+9273.19743202j)   \n",
       "2  (-147.742534269+36.9325361747j)  (6872.42733148-5896.04177095j)   \n",
       "3  (-34.4666359745-125.945142273j)   (3111.3085742+10029.0444708j)   \n",
       "4   (118.231513568+61.7688141911j)  (11006.5745471+5095.22134146j)   \n",
       "\n",
       "                             m_jjj                             m_lv  \\\n",
       "0               (18126930.3969+0j)               (8542375.21261+0j)   \n",
       "1  (-549.237713651+13601.9247298j)   (128.300496094-453.924667721j)   \n",
       "2   (20083.3732922-3461.22101082j)   (-1816.83410464+341.95447713j)   \n",
       "3  (-3882.78527776+2390.60150768j)  (-399.011978123+3103.97430008j)   \n",
       "4   (12538.4120959-9957.91739448j)  (-1122.23583873-1697.77577789j)   \n",
       "\n",
       "                             m_jlv                             m_bb  \\\n",
       "0               (19404433.3865+0j)               (11982746.0311+0j)   \n",
       "1   (11566.0863809+19364.8912835j)   (13120.2128331+3103.74473599j)   \n",
       "2   (8147.31831542+12612.6752749j)   (4322.52347107+405.753495554j)   \n",
       "3    (-18134.268758+4369.8005329j)  (-4335.76489347-19327.3488033j)   \n",
       "4  (-6828.50096709-587.104477543j)  (-12066.1287332+1709.35739797j)   \n",
       "\n",
       "                             m_wbb                           m_wwbb  \n",
       "0               (34842988.1681+0j)               (48405143.0547+0j)  \n",
       "1    (18093.0082823+29863.944389j)    (31306.838205+20385.8465256j)  \n",
       "2   (17668.7951018+40323.1110574j)   (24431.9202624+32478.0342892j)  \n",
       "3  (-4198.80052076+8739.59602611j)   (11179.4873673-3632.49985006j)  \n",
       "4  (-27544.0632036+2421.36229569j)  (-41289.9915709-5265.04432711j)  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   1 out of 2047 | elapsed:    0.5s remaining: 17.0min\n",
      "[Parallel(n_jobs=16)]: Done 3000 out of 3000 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "# predict test sample\n",
    "kaggle_proba = get_result(fitter, new_test, new_features)\n",
    "kaggle_ids = test.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='datasets/baseline.csv' target='_blank'>datasets/baseline.csv</a><br>"
      ],
      "text/plain": [
       "/notebooks/higgs_kaggle/datasets/baseline.csv"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "def create_solution(ids, proba, filename='baseline.csv'):\n",
    "    \"\"\"saves predictions to file and provides a link for downloading \"\"\"\n",
    "    pandas.DataFrame({'event_id': ids, 'prediction': proba}).to_csv('datasets/{}'.format(filename), index=False)\n",
    "    return FileLink('datasets/{}'.format(filename))\n",
    "    \n",
    "create_solution(kaggle_ids, kaggle_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
