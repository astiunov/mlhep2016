{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "In this notebook we prepare a simple solution for the [kaggle challenge on higgs.](https://inclass.kaggle.com/c/mlhep-2016-higgs-detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd datasets; wget -O public_train_10000.root -nc --no-check-certificate https://2016.mlhep.yandex.net/data/higgs/public_train_10000.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can download training sample with 100000 available events\n",
    "# uncomment the below row\n",
    "!cd datasets; wget -O public_train_100000.root -nc --no-check-certificate https://2016.mlhep.yandex.net/data/higgs/public_train_100000.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd datasets; wget -O public_test.root -nc --no-check-certificate https://2016.mlhep.yandex.net/data/higgs/public_test.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the smallest part of training file and test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import root_numpy\n",
    "data = pandas.DataFrame(root_numpy.root2array('datasets/public_train_100000.root'))\n",
    "test = pandas.DataFrame(root_numpy.root2array('datasets/public_test.root'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training features\n",
    "\n",
    "Exclude `event_id`, `target` from the features set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jet3_pt',\n",
       " 'jet3_eta',\n",
       " 'm_jjj',\n",
       " 'mem_phi',\n",
       " 'jet1_pt',\n",
       " 'jet4_phi',\n",
       " 'jet1_phi',\n",
       " 'jet2_eta',\n",
       " 'jet3_btag',\n",
       " 'm_jlv',\n",
       " 'm_wbb',\n",
       " 'jet4_pt',\n",
       " 'jet4_btag',\n",
       " 'jet2_pt',\n",
       " 'jet1_btag',\n",
       " 'm_jj',\n",
       " 'm_wwbb',\n",
       " 'jet2_phi',\n",
       " 'lepton_phi',\n",
       " 'm_bb',\n",
       " 'm_lv',\n",
       " 'jet4_eta',\n",
       " 'jet2_btag',\n",
       " 'lepton_pt',\n",
       " 'mem_pt',\n",
       " 'lepton_eta',\n",
       " 'jet3_phi',\n",
       " 'jet1_eta']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(set(data.columns) - {'event_id', 'target'})\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare high-level features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_level_features = ['m_jj', 'm_jjj', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'm_lv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histograms for each high-level feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_params = {'normed': True, 'bins': 60, 'alpha': 0.4}\n",
    "# create the figure\n",
    "plt.figure(figsize=(16, 25))\n",
    "for n, feature in enumerate(high_level_features):\n",
    "    # add sub plot on our figure\n",
    "    plt.subplot(len(features) // 5 + 1, 3, n+1)\n",
    "    # define range for histograms by cutting 1% of data from both ends\n",
    "    min_value, max_value = numpy.percentile(data[feature], [1, 99])\n",
    "    plt.hist(data.ix[data.target.values == 0, feature].values, range=(min_value, max_value), \n",
    "             label='class 0', **hist_params)\n",
    "    plt.hist(data.ix[data.target.values == 1, feature].values, range=(min_value, max_value), \n",
    "             label='class 1', **hist_params)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def get_validated_trained(fitter, data, features, part):\n",
    "    training_data, validation_data = train_test_split(data, random_state=3747824, train_size=part)\n",
    "    fitter.fit(training_data[features], training_data.target)\n",
    "    results = fitter.predict_proba(validation_data[features])\n",
    "    print 'Validation:', roc_auc_score(validation_data.target, results[:, 1])\n",
    "\n",
    "def get_full_trained(fitter, data, features):\n",
    "    fitter.fit(data[features], data.target)\n",
    "\n",
    "def get_result(fitter, test, features):\n",
    "    return fitter.predict_proba(test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of 1847 | elapsed:    0.5s remaining: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=16)]: Done   1 out of  34 | elapsed:    0.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 5000 out of 5000 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 0.796521417074\n"
     ]
    }
   ],
   "source": [
    "def get_fitter():\n",
    "    fitter = RandomForestClassifier(\n",
    "        5000,\n",
    "        max_depth=30,\n",
    "        n_jobs=-1,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return fitter\n",
    "\n",
    "fitter = get_fitter()\n",
    "cur_features = features\n",
    "\"\"\"for i in range(1, 5):\n",
    "    var_name = 'jet%d_eta' % i\n",
    "    new_var_name = 'jet%d_eta_norm' % i\n",
    "    cur_features.append(new_var_name)\n",
    "    data[new_var_name] = 2 * np.arctan(np.exp(-data[var_name]))\n",
    "    data[new_var_name] = 2 * np.arctan(np.exp(-data[var_name]))\"\"\"\n",
    "#get_full_trained(fitter, data, cur_features)\n",
    "get_validated_trained(fitter, data, cur_features, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = fitter.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in fitter.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print \"Feature ranking:\"\n",
    "\n",
    "X = data[cur_features]\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print \"%d. feature %d %s (%f)\" % (f + 1, indices[f], cur_features[f], importances[indices[f]])\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   1 out of 2000 | elapsed:    0.5s remaining: 17.2min\n",
      "[Parallel(n_jobs=16)]: Done 2000 out of 2000 | elapsed:   38.4s finished\n"
     ]
    }
   ],
   "source": [
    "# predict test sample\n",
    "kaggle_proba = get_result(fitter, test, cur_features)\n",
    "kaggle_ids = test.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='datasets/baseline.csv' target='_blank'>datasets/baseline.csv</a><br>"
      ],
      "text/plain": [
       "/notebooks/higgs_kaggle/datasets/baseline.csv"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "def create_solution(ids, proba, filename='baseline.csv'):\n",
    "    \"\"\"saves predictions to file and provides a link for downloading \"\"\"\n",
    "    pandas.DataFrame({'event_id': ids, 'prediction': proba}).to_csv('datasets/{}'.format(filename), index=False)\n",
    "    return FileLink('datasets/{}'.format(filename))\n",
    "    \n",
    "create_solution(kaggle_ids, kaggle_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
