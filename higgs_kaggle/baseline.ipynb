{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "In this notebook we prepare a simple solution for the [kaggle challenge on higgs.](https://inclass.kaggle.com/c/mlhep-2016-higgs-detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd datasets; wget -O public_train_10000.root -nc --no-check-certificate https://2016.mlhep.yandex.net/data/higgs/public_train_10000.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can download training sample with 100000 available events\n",
    "# uncomment the below row\n",
    "!cd datasets; wget -O public_train_100000.root -nc --no-check-certificate https://2016.mlhep.yandex.net/data/higgs/public_train_100000.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd datasets; wget -O public_test.root -nc --no-check-certificate https://2016.mlhep.yandex.net/data/higgs/public_test.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /root/miniconda/envs/rep_py2/lib/libcrypto.so.1.0.0: no version information available (required by wget)\n",
      "wget: /root/miniconda/envs/rep_py2/lib/libssl.so.1.0.0: no version information available (required by wget)\n",
      "--2016-06-23 09:56:40--  https://transfer.sh/Bvy4H/test-sorted.root\n",
      "Resolving transfer.sh (transfer.sh)... 64:ff9b::3433:a179, 64:ff9b::3412:7e25\n",
      "Connecting to transfer.sh (transfer.sh)|64:ff9b::3433:a179|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 92696730 (88M)\n",
      "Saving to: 'test_sorted.root'\n",
      "\n",
      "100%[======================================>] 92,696,730  13.2MB/s   in 10s    \n",
      "\n",
      "2016-06-23 09:56:50 (8.64 MB/s) - 'test_sorted.root' saved [92696730/92696730]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd datasets; wget -O test_sorted.root -nc --no-check-certificate https://transfer.sh/Bvy4H/test-sorted.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the smallest part of training file and test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>target</th>\n",
       "      <th>lepton_pt</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>mem_pt</th>\n",
       "      <th>mem_phi</th>\n",
       "      <th>jet1_pt</th>\n",
       "      <th>jet1_eta</th>\n",
       "      <th>jet1_phi</th>\n",
       "      <th>...</th>\n",
       "      <th>jet4_phi</th>\n",
       "      <th>jet4_btag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "      <th>__index__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1</td>\n",
       "      <td>34.750568</td>\n",
       "      <td>0.787025</td>\n",
       "      <td>1.898891</td>\n",
       "      <td>20.862434</td>\n",
       "      <td>-2.622998</td>\n",
       "      <td>79.948036</td>\n",
       "      <td>0.877472</td>\n",
       "      <td>-0.256736</td>\n",
       "      <td>...</td>\n",
       "      <td>2.631595</td>\n",
       "      <td>2.000023</td>\n",
       "      <td>81.724449</td>\n",
       "      <td>189.583145</td>\n",
       "      <td>80.118317</td>\n",
       "      <td>170.086075</td>\n",
       "      <td>91.128204</td>\n",
       "      <td>298.468781</td>\n",
       "      <td>374.685760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>1</td>\n",
       "      <td>54.250927</td>\n",
       "      <td>-1.057915</td>\n",
       "      <td>2.310697</td>\n",
       "      <td>51.167873</td>\n",
       "      <td>2.545749</td>\n",
       "      <td>71.681404</td>\n",
       "      <td>-1.139118</td>\n",
       "      <td>-1.300325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.837746</td>\n",
       "      <td>201.096756</td>\n",
       "      <td>83.321556</td>\n",
       "      <td>208.039688</td>\n",
       "      <td>67.118484</td>\n",
       "      <td>287.363983</td>\n",
       "      <td>527.247559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>1</td>\n",
       "      <td>47.746025</td>\n",
       "      <td>-0.783184</td>\n",
       "      <td>2.660325</td>\n",
       "      <td>68.165527</td>\n",
       "      <td>-1.700790</td>\n",
       "      <td>118.880913</td>\n",
       "      <td>-0.211263</td>\n",
       "      <td>1.326902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.316925</td>\n",
       "      <td>156.334732</td>\n",
       "      <td>95.307602</td>\n",
       "      <td>149.089005</td>\n",
       "      <td>130.389206</td>\n",
       "      <td>237.879318</td>\n",
       "      <td>336.058838</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>0</td>\n",
       "      <td>45.950066</td>\n",
       "      <td>1.613817</td>\n",
       "      <td>0.964722</td>\n",
       "      <td>39.302082</td>\n",
       "      <td>-0.075989</td>\n",
       "      <td>84.307426</td>\n",
       "      <td>0.465748</td>\n",
       "      <td>2.287783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.032066</td>\n",
       "      <td>182.341537</td>\n",
       "      <td>81.941925</td>\n",
       "      <td>164.411148</td>\n",
       "      <td>93.709511</td>\n",
       "      <td>237.900055</td>\n",
       "      <td>392.807831</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>0</td>\n",
       "      <td>44.409187</td>\n",
       "      <td>-0.228907</td>\n",
       "      <td>-1.837974</td>\n",
       "      <td>49.886654</td>\n",
       "      <td>0.156533</td>\n",
       "      <td>138.741928</td>\n",
       "      <td>0.293522</td>\n",
       "      <td>1.391425</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.192486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.030174</td>\n",
       "      <td>288.594086</td>\n",
       "      <td>84.386459</td>\n",
       "      <td>150.299744</td>\n",
       "      <td>69.818291</td>\n",
       "      <td>435.990356</td>\n",
       "      <td>533.977905</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id  target  lepton_pt  lepton_eta  lepton_phi     mem_pt   mem_phi  \\\n",
       "0   1000001       1  34.750568    0.787025    1.898891  20.862434 -2.622998   \n",
       "1   1000002       1  54.250927   -1.057915    2.310697  51.167873  2.545749   \n",
       "2   1000003       1  47.746025   -0.783184    2.660325  68.165527 -1.700790   \n",
       "3   1000004       0  45.950066    1.613817    0.964722  39.302082 -0.075989   \n",
       "4   1000005       0  44.409187   -0.228907   -1.837974  49.886654  0.156533   \n",
       "\n",
       "      jet1_pt  jet1_eta  jet1_phi    ...      jet4_phi  jet4_btag        m_jj  \\\n",
       "0   79.948036  0.877472 -0.256736    ...      2.631595   2.000023   81.724449   \n",
       "1   71.681404 -1.139118 -1.300325    ...     -0.737298   0.000000   65.837746   \n",
       "2  118.880913 -0.211263  1.326902    ...     -0.626912   0.000000   69.316925   \n",
       "3   84.307426  0.465748  2.287783    ...     -0.850500   0.000000   71.032066   \n",
       "4  138.741928  0.293522  1.391425    ...     -1.192486   0.000000  122.030174   \n",
       "\n",
       "        m_jjj       m_lv       m_jlv        m_bb       m_wbb      m_wwbb  \\\n",
       "0  189.583145  80.118317  170.086075   91.128204  298.468781  374.685760   \n",
       "1  201.096756  83.321556  208.039688   67.118484  287.363983  527.247559   \n",
       "2  156.334732  95.307602  149.089005  130.389206  237.879318  336.058838   \n",
       "3  182.341537  81.941925  164.411148   93.709511  237.900055  392.807831   \n",
       "4  288.594086  84.386459  150.299744   69.818291  435.990356  533.977905   \n",
       "\n",
       "   __index__  \n",
       "0          0  \n",
       "1          1  \n",
       "2          2  \n",
       "3          3  \n",
       "4          4  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import root_numpy\n",
    "#data = pandas.DataFrame(root_numpy.root2array('datasets/public_train_100000.root'))\n",
    "data = pandas.DataFrame(root_numpy.root2array('datasets/public_train_100000_sorted.root'))\n",
    "test = pandas.DataFrame(root_numpy.root2array('datasets/test_sorted.root'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 30)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training features\n",
    "\n",
    "Exclude `event_id`, `target` from the features set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jet3_pt',\n",
       " 'jet3_eta',\n",
       " 'm_jjj',\n",
       " 'mem_phi',\n",
       " 'jet1_pt',\n",
       " 'jet4_phi',\n",
       " 'jet1_phi',\n",
       " 'jet2_eta',\n",
       " 'm_jlv',\n",
       " 'm_wbb',\n",
       " 'jet4_pt',\n",
       " 'jet2_pt',\n",
       " 'm_jj',\n",
       " 'm_wwbb',\n",
       " 'jet2_phi',\n",
       " 'lepton_phi',\n",
       " 'm_bb',\n",
       " 'm_lv',\n",
       " 'jet4_eta',\n",
       " 'lepton_pt',\n",
       " 'mem_pt',\n",
       " 'lepton_eta',\n",
       " 'jet3_phi',\n",
       " 'jet1_eta']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(set(data.columns) - {'event_id', 'target', '__index__',\n",
    "                                     'jet1_btag', 'jet2_btag', 'jet3_btag', 'jet4_btag'})\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare high-level features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "new_data = data.copy()\n",
    "new_test = test.copy()\n",
    "new_features = features[:]\n",
    "for m1, m2 in combinations([i for i in data.columns if 'm_' in i and '?' not in i and 'mem' not in i], 2):\n",
    "    if len(m1) < len(m2):\n",
    "        m1, m2 = m2, m1\n",
    "    new_data['?'+m1+'/'+m2] = data[m1].values / data[m2].values\n",
    "    new_test['?'+m1+'/'+m2] = test[m1].values / test[m2].values\n",
    "    new_features.append('?'+m1+'/'+m2)\n",
    "new_data['sum_pt'] = data.jet1_pt + data.jet2_pt + data.jet3_pt + data.jet4_pt + data.lepton_pt + data.mem_pt\n",
    "new_test['sum_pt'] = test.jet1_pt + test.jet2_pt + test.jet3_pt + test.jet4_pt + test.lepton_pt + test.mem_pt\n",
    "new_features.append('sum_pt')\n",
    "new_data['sum_jet_pt'] = data.jet1_pt + data.jet2_pt + data.jet3_pt + data.jet4_pt\n",
    "new_test['sum_jet_pt'] = test.jet1_pt + test.jet2_pt + test.jet3_pt + test.jet4_pt\n",
    "new_features.append('sum_jet_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jet3_pt',\n",
       " 'jet3_eta',\n",
       " 'm_jjj',\n",
       " 'mem_phi',\n",
       " 'jet1_pt',\n",
       " 'jet4_phi',\n",
       " 'jet1_phi',\n",
       " 'jet2_eta',\n",
       " 'm_jlv',\n",
       " 'm_wbb',\n",
       " 'jet4_pt',\n",
       " 'jet2_pt',\n",
       " 'm_jj',\n",
       " 'm_wwbb',\n",
       " 'jet2_phi',\n",
       " 'lepton_phi',\n",
       " 'm_bb',\n",
       " 'm_lv',\n",
       " 'jet4_eta',\n",
       " 'lepton_pt',\n",
       " 'mem_pt',\n",
       " 'lepton_eta',\n",
       " 'jet3_phi',\n",
       " 'jet1_eta',\n",
       " '?m_jjj/m_jj',\n",
       " '?m_jj/m_lv',\n",
       " '?m_jlv/m_jj',\n",
       " '?m_jj/m_bb',\n",
       " '?m_wbb/m_jj',\n",
       " '?m_wwbb/m_jj',\n",
       " '?m_jjj/m_lv',\n",
       " '?m_jjj/m_jlv',\n",
       " '?m_jjj/m_bb',\n",
       " '?m_jjj/m_wbb',\n",
       " '?m_wwbb/m_jjj',\n",
       " '?m_jlv/m_lv',\n",
       " '?m_lv/m_bb',\n",
       " '?m_wbb/m_lv',\n",
       " '?m_wwbb/m_lv',\n",
       " '?m_jlv/m_bb',\n",
       " '?m_jlv/m_wbb',\n",
       " '?m_wwbb/m_jlv',\n",
       " '?m_wbb/m_bb',\n",
       " '?m_wwbb/m_bb',\n",
       " '?m_wwbb/m_wbb',\n",
       " 'sum_pt',\n",
       " 'sum_jet_pt']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histograms for each high-level feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_params = {'normed': True, 'bins': 60, 'alpha': 0.4}\n",
    "# create the figure\n",
    "plt.figure(figsize=(16, 25))\n",
    "for n, feature in enumerate(high_level_features):\n",
    "    # add sub plot on our figure\n",
    "    plt.subplot(len(features) // 5 + 1, 3, n+1)\n",
    "    # define range for histograms by cutting 1% of data from both ends\n",
    "    min_value, max_value = numpy.percentile(data[feature], [1, 99])\n",
    "    plt.hist(data.ix[data.target.values == 0, feature].values, range=(min_value, max_value), \n",
    "             label='class 0', **hist_params)\n",
    "    plt.hist(data.ix[data.target.values == 1, feature].values, range=(min_value, max_value), \n",
    "             label='class 1', **hist_params)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def get_validated_trained(fitter, data, features, part):\n",
    "    training_data, validation_data = train_test_split(data, random_state=3747824, train_size=part)\n",
    "    fitter.fit(training_data[features], training_data.target)\n",
    "    results = fitter.predict_proba(validation_data[features])\n",
    "    print 'Validation:', roc_auc_score(validation_data.target, results[:, 1])\n",
    "\n",
    "def get_full_trained(fitter, data, features):\n",
    "    fitter.fit(data[features], data.target)\n",
    "\n",
    "def get_result(fitter, test, features):\n",
    "    return fitter.predict_proba(test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Input array is not in image shape, and could not assume a square.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-2ed040407914>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mcur_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mget_validated_trained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-81-b70508ac85a8>\u001b[0m in \u001b[0;36mget_validated_trained\u001b[1;34m(fitter, data, features, part)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_validated_trained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3747824\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mfitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Validation:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/miniconda/envs/rep_py2/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \"\"\"\n\u001b[0;32m    164\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/miniconda/envs/rep_py2/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;31m# Now train based on a problem transformed into regression.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/miniconda/envs/rep_py2/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mknown_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mdata_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{:,}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mknown_size\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'N/A'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/miniconda/envs/rep_py2/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36m_reshape\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                 \u001b[1;34m\"Input array is not in image shape, and could not assume a square.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_convolution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Input array is not in image shape, and could not assume a square."
     ]
    }
   ],
   "source": [
    "from sknn.mlp import Classifier, Layer, Convolution\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout\n",
    ")\n",
    "logger = logging.getLogger('sknn')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "fitter = Pipeline([\n",
    "        ('min/max scaler', MinMaxScaler(feature_range=(0.0, 1.0))),\n",
    "        ('neural network', Classifier(\n",
    "                layers=[\n",
    "                    Convolution(\"Sigmoid\", channels=8, kernel_shape=(3,3)),\n",
    "                    Layer(\"Rectifier\", units=300),\n",
    "                    Layer(\"Rectifier\", units=300),\n",
    "                    Layer(\"Softmax\")\n",
    "                ],\n",
    "                n_iter=50,\n",
    "                random_state=274734,\n",
    "                learning_rate=0.21,\n",
    "                learning_momentum=0.999,\n",
    "                verbose=True,\n",
    "                batch_size=10,\n",
    "                regularize='L2',\n",
    "                weight_decay=0.00001\n",
    "    ))])\n",
    "\n",
    "cur_features = features\n",
    "get_validated_trained(fitter, data, cur_features, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_estimators=300, eta=0.02, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.02, max_depth=8, score=0.802537 -  40.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:   40.9s\n",
      "[CV] n_estimators=300, eta=0.02, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.02, max_depth=8, score=0.808590 -  40.3s\n",
      "[Parallel(n_jobs=1)]: Done   2 jobs       | elapsed:  1.4min\n",
      "[CV] n_estimators=300, eta=0.02, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.02, max_depth=8, score=0.804838 -  40.9s\n",
      "[Parallel(n_jobs=1)]: Done   3 jobs       | elapsed:  2.0min\n",
      "[CV] n_estimators=300, eta=0.03, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.03, max_depth=8, score=0.802397 -  48.1s\n",
      "[Parallel(n_jobs=1)]: Done   4 jobs       | elapsed:  2.8min\n",
      "[CV] n_estimators=300, eta=0.03, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.03, max_depth=8, score=0.808903 -  39.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 jobs       | elapsed:  3.5min\n",
      "[CV] n_estimators=300, eta=0.03, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.03, max_depth=8, score=0.804241 -  39.1s\n",
      "[Parallel(n_jobs=1)]: Done   6 jobs       | elapsed:  4.1min\n",
      "[CV] n_estimators=300, eta=0.04, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.04, max_depth=8, score=0.801462 -  48.7s\n",
      "[Parallel(n_jobs=1)]: Done   7 jobs       | elapsed:  4.9min\n",
      "[CV] n_estimators=300, eta=0.04, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.04, max_depth=8, score=0.809175 -  47.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 jobs       | elapsed:  5.7min\n",
      "[CV] n_estimators=300, eta=0.04, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.04, max_depth=8, score=0.804282 -  39.5s\n",
      "[Parallel(n_jobs=1)]: Done   9 jobs       | elapsed:  6.4min\n",
      "[CV] n_estimators=300, eta=0.05, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.05, max_depth=8, score=0.801396 -  39.5s\n",
      "[Parallel(n_jobs=1)]: Done  10 jobs       | elapsed:  7.1min\n",
      "[CV] n_estimators=300, eta=0.05, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.05, max_depth=8, score=0.808910 -  40.2s\n",
      "[Parallel(n_jobs=1)]: Done  11 jobs       | elapsed:  7.7min\n",
      "[CV] n_estimators=300, eta=0.05, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.05, max_depth=8, score=0.803699 -  42.4s\n",
      "[Parallel(n_jobs=1)]: Done  12 jobs       | elapsed:  8.4min\n",
      "[CV] n_estimators=300, eta=0.06, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.06, max_depth=8, score=0.800621 -  44.1s\n",
      "[Parallel(n_jobs=1)]: Done  13 jobs       | elapsed:  9.2min\n",
      "[CV] n_estimators=300, eta=0.06, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.06, max_depth=8, score=0.807277 -  44.2s\n",
      "[Parallel(n_jobs=1)]: Done  14 jobs       | elapsed:  9.9min\n",
      "[CV] n_estimators=300, eta=0.06, max_depth=8 .........................\n",
      "[CV]  n_estimators=300, eta=0.06, max_depth=8, score=0.803515 -  44.5s\n",
      "[Parallel(n_jobs=1)]: Done  15 jobs       | elapsed: 10.6min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 10.6min finished\n",
      "Validation: 0.81066018691\n",
      "{'n_estimators': 300, 'eta': 0.02, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "from rep.estimators import XGBoostClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "tuned_parameters = {\n",
    "    'max_depth': [8],\n",
    "    'n_estimators': [300],\n",
    "    'eta': [0.02, 0.03, 0.04, 0.05, 0.06]\n",
    "}\n",
    "fitter = GridSearchCV(XGBoostClassifier(\n",
    "        #max_depth=13,\n",
    "        #n_estimators=300,\n",
    "), tuned_parameters, scoring='roc_auc', verbose=100500)\n",
    "get_validated_trained(fitter, new_data.astype('float'), new_features, 0.7)\n",
    "#get_full_trained(fitter, data, features)\n",
    "print fitter.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] n_estimators=700, learning_rate=0.2 .............................\n",
      "[CV] .... n_estimators=700, learning_rate=0.2, score=0.777832 - 3.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:  3.5min\n",
      "[CV] n_estimators=700, learning_rate=0.2 .............................\n",
      "[CV] .... n_estimators=700, learning_rate=0.2, score=0.785885 - 3.7min\n",
      "[Parallel(n_jobs=1)]: Done   2 jobs       | elapsed:  7.3min\n",
      "[CV] n_estimators=700, learning_rate=0.2 .............................\n",
      "[CV] .... n_estimators=700, learning_rate=0.2, score=0.783012 - 3.5min\n",
      "[Parallel(n_jobs=1)]: Done   3 jobs       | elapsed: 10.8min\n",
      "[CV] n_estimators=700, learning_rate=0.3 .............................\n",
      "[CV] .... n_estimators=700, learning_rate=0.3, score=0.778066 - 3.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 jobs       | elapsed: 14.3min\n",
      "[CV] n_estimators=700, learning_rate=0.3 .............................\n",
      "[CV] .... n_estimators=700, learning_rate=0.3, score=0.786863 - 3.6min\n",
      "[Parallel(n_jobs=1)]: Done   5 jobs       | elapsed: 17.8min\n",
      "[CV] n_estimators=700, learning_rate=0.3 .............................\n",
      "[CV] .... n_estimators=700, learning_rate=0.3, score=0.783137 - 3.5min\n",
      "[Parallel(n_jobs=1)]: Done   6 jobs       | elapsed: 21.3min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 21.3min finished\n",
      "Validation: 0.785651827503\n",
      "{'n_estimators': 700, 'learning_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "tuned_parameters = {\n",
    "    #'alpha': [0.0001],\n",
    "    #'power_t': [0.1, 0.5, 0.7],\n",
    "    #'n_iter': [42, 66, 77, 100]\n",
    "    'n_estimators': [700],\n",
    "    'learning_rate': [0.2, 0.3]\n",
    "}\n",
    "boost_fitter = AdaBoostClassifier()\n",
    "grid_fitter = GridSearchCV(boost_fitter, tuned_parameters,\n",
    "                              scoring='roc_auc', verbose=100500)\n",
    "fitter = Pipeline([\n",
    "        ('min/max scaler', MinMaxScaler(feature_range=(0.0, 1.0))),\n",
    "        ('grid', grid_fitter)])\n",
    "get_validated_trained(fitter, new_data.astype('float'), new_features, 0.7)\n",
    "#get_full_trained(fitter, data, features)\n",
    "print grid_fitter.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitter = XGBoostClassifier(\n",
    "    max_depth=8,\n",
    "    n_estimators=300,\n",
    "    eta=0.02\n",
    ")\n",
    "#get_validated_trained(fitter, data.astype('float'), features, 0.7)\n",
    "get_full_trained(fitter, new_data.astype('float'), new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict test sample\n",
    "kaggle_proba = get_result(fitter, new_test.astype('float'), new_features)\n",
    "kaggle_ids = test.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='datasets/xgboost.csv' target='_blank'>datasets/xgboost.csv</a><br>"
      ],
      "text/plain": [
       "/notebooks/higgs_kaggle/datasets/xgboost.csv"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "def create_solution(ids, proba, filename='xgboost.csv'):\n",
    "    \"\"\"saves predictions to file and provides a link for downloading \"\"\"\n",
    "    pandas.DataFrame({'event_id': ids, 'prediction': proba}).to_csv('datasets/{}'.format(filename), index=False)\n",
    "    return FileLink('datasets/{}'.format(filename))\n",
    "    \n",
    "create_solution(kaggle_ids.astype(np.int32), kaggle_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
